"use strict";
var __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {
    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }
    return new (P || (P = Promise))(function (resolve, reject) {
        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }
        function rejected(value) { try { step(generator["throw"](value)); } catch (e) { reject(e); } }
        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }
        step((generator = generator.apply(thisArg, _arguments || [])).next());
    });
};
var __asyncValues = (this && this.__asyncValues) || function (o) {
    if (!Symbol.asyncIterator) throw new TypeError("Symbol.asyncIterator is not defined.");
    var m = o[Symbol.asyncIterator], i;
    return m ? m.call(o) : (o = typeof __values === "function" ? __values(o) : o[Symbol.iterator](), i = {}, verb("next"), verb("throw"), verb("return"), i[Symbol.asyncIterator] = function () { return this; }, i);
    function verb(n) { i[n] = o[n] && function (v) { return new Promise(function (resolve, reject) { v = o[n](v), settle(resolve, reject, v.done, v.value); }); }; }
    function settle(resolve, reject, d, v) { Promise.resolve(v).then(function(v) { resolve({ value: v, done: d }); }, reject); }
};
Object.defineProperty(exports, "__esModule", { value: true });
const DataMapper_1 = require("./DataMapper");
const ItemNotFoundException_1 = require("./ItemNotFoundException");
const protocols_1 = require("./protocols");
const os_1 = require("os");
const process_1 = require("process");
const client_dynamodb_1 = require("@aws-sdk/client-dynamodb");
const dynamodb_expressions_1 = require("@awslabs-community-fork/dynamodb-expressions");
const nestedDocumentDef = {
    type: 'Document',
    members: {
        foo: { type: 'String' }
    }
};
nestedDocumentDef.members.recursive = nestedDocumentDef;
const [seconds, nanoseconds] = process_1.hrtime();
const TableName = `mapper-integ-${seconds}-${nanoseconds}-${os_1.hostname()}`;
const schema = {
    key: {
        type: 'Number',
        attributeName: 'testIndex',
        keyType: 'HASH',
    },
    timestamp: { type: 'Date' },
    data: nestedDocumentDef,
    tuple: {
        type: 'Tuple',
        members: [
            { type: 'Boolean' },
            { type: 'String' },
        ]
    },
    scanIdentifier: { type: 'Number' }
};
class TestRecord {
}
Object.defineProperties(TestRecord.prototype, {
    [protocols_1.DynamoDbSchema]: { value: schema },
    [protocols_1.DynamoDbTable]: { value: TableName },
});
describe('DataMapper', () => {
    let idx = 0;
    const ddbClient = new client_dynamodb_1.DynamoDB({});
    const mapper = new DataMapper_1.DataMapper({ client: ddbClient });
    jest.setTimeout(60000);
    beforeAll(() => {
        return mapper.ensureTableExists(TestRecord, {
            readCapacityUnits: 10,
            writeCapacityUnits: 10,
        });
    });
    afterAll(() => {
        return mapper.ensureTableNotExists(TestRecord);
    });
    it('should save and load objects', () => __awaiter(void 0, void 0, void 0, function* () {
        const key = idx++;
        const mapper = new DataMapper_1.DataMapper({ client: ddbClient });
        const timestamp = new Date();
        // subsecond precision will not survive the trip through the serializer,
        // as DynamoDB's ttl fields use unix epoch (second precision) timestamps
        timestamp.setMilliseconds(0);
        const item = new TestRecord();
        item.key = key;
        item.timestamp = timestamp;
        item.data = {
            recursive: {
                recursive: {
                    recursive: {
                        foo: '',
                    },
                },
            },
        };
        expect(yield mapper.put(item)).toEqual(item);
        expect(yield mapper.get(item, { readConsistency: 'strong' }))
            .toEqual(item);
    }));
    it('should delete objects', () => __awaiter(void 0, void 0, void 0, function* () {
        const key = idx++;
        const mapper = new DataMapper_1.DataMapper({ client: ddbClient });
        const timestamp = new Date();
        // subsecond precision will not survive the trip through the serializer,
        // as DynamoDB's ttl fields use unix epoch (second precision) timestamps
        timestamp.setMilliseconds(0);
        const item = new TestRecord();
        item.key = key;
        item.timestamp = timestamp;
        item.data = {
            recursive: {
                recursive: {
                    recursive: {
                        foo: '',
                    },
                },
            },
        };
        yield mapper.put(item);
        yield expect(mapper.get(item, { readConsistency: 'strong' })).resolves;
        yield mapper.delete(item);
        yield expect(mapper.get(item, { readConsistency: 'strong' }))
            .rejects
            .toMatchObject(new ItemNotFoundException_1.ItemNotFoundException({
            TableName,
            ConsistentRead: true,
            Key: { testIndex: { N: key.toString(10) } }
        }));
    }));
    it('should scan objects', () => __awaiter(void 0, void 0, void 0, function* () {
        var e_1, _a, e_2, _b;
        const keys = [];
        const mapper = new DataMapper_1.DataMapper({ client: ddbClient });
        const scanIdentifier = Date.now();
        const items = [];
        for (let i = 0; i < 30; i++) {
            const item = new TestRecord();
            item.key = idx++;
            item.tuple = [item.key % 2 === 0, 'string'];
            item.scanIdentifier = scanIdentifier;
            keys.push(item.key);
            items.push(item);
        }
        try {
            for (var _c = __asyncValues(mapper.batchPut(items)), _d; _d = yield _c.next(), !_d.done;) {
                const _ = _d.value;
            }
        }
        catch (e_1_1) { e_1 = { error: e_1_1 }; }
        finally {
            try {
                if (_d && !_d.done && (_a = _c.return)) yield _a.call(_c);
            }
            finally { if (e_1) throw e_1.error; }
        }
        const results = [];
        try {
            for (var _e = __asyncValues(mapper.scan(TestRecord, {
                readConsistency: 'strong',
                filter: Object.assign(Object.assign({}, dynamodb_expressions_1.equals(scanIdentifier)), { subject: 'scanIdentifier' }),
            })), _f; _f = yield _e.next(), !_f.done;) {
                const element = _f.value;
                results.push(element);
            }
        }
        catch (e_2_1) { e_2 = { error: e_2_1 }; }
        finally {
            try {
                if (_f && !_f.done && (_b = _e.return)) yield _b.call(_e);
            }
            finally { if (e_2) throw e_2.error; }
        }
        expect(results.sort((a, b) => a.key - b.key)).toEqual(keys.map(key => {
            const record = new TestRecord();
            record.key = key;
            record.scanIdentifier = scanIdentifier;
            record.tuple = [key % 2 === 0, 'string'];
            return record;
        }));
    }));
    it('should scan objects in parallel', () => __awaiter(void 0, void 0, void 0, function* () {
        var e_3, _g, e_4, _h;
        const keys = [];
        const mapper = new DataMapper_1.DataMapper({ client: ddbClient });
        const scanIdentifier = Date.now();
        const items = [];
        for (let i = 0; i < 10; i++) {
            const item = new TestRecord();
            item.key = idx++;
            item.tuple = [item.key % 2 === 0, 'string'];
            item.scanIdentifier = scanIdentifier;
            keys.push(item.key);
            items.push(item);
        }
        try {
            for (var _j = __asyncValues(mapper.batchPut(items)), _k; _k = yield _j.next(), !_k.done;) {
                const _ = _k.value;
            }
        }
        catch (e_3_1) { e_3 = { error: e_3_1 }; }
        finally {
            try {
                if (_k && !_k.done && (_g = _j.return)) yield _g.call(_j);
            }
            finally { if (e_3) throw e_3.error; }
        }
        const results = [];
        try {
            for (var _l = __asyncValues(mapper.parallelScan(TestRecord, 4, {
                readConsistency: 'strong',
                filter: Object.assign(Object.assign({}, dynamodb_expressions_1.equals(scanIdentifier)), { subject: 'scanIdentifier' }),
            })), _m; _m = yield _l.next(), !_m.done;) {
                const element = _m.value;
                results.push(element);
            }
        }
        catch (e_4_1) { e_4 = { error: e_4_1 }; }
        finally {
            try {
                if (_m && !_m.done && (_h = _l.return)) yield _h.call(_l);
            }
            finally { if (e_4) throw e_4.error; }
        }
        expect(results.sort((a, b) => a.key - b.key)).toEqual(keys.map(key => {
            const record = new TestRecord();
            record.key = key;
            record.scanIdentifier = scanIdentifier;
            record.tuple = [key % 2 === 0, 'string'];
            return record;
        }));
    }));
    it('should query objects', () => __awaiter(void 0, void 0, void 0, function* () {
        var e_5, _o;
        const mapper = new DataMapper_1.DataMapper({ client: ddbClient });
        const item = new TestRecord();
        item.key = idx++;
        item.tuple = [item.key % 2 === 0, 'string'];
        yield mapper.put({ item });
        try {
            for (var _p = __asyncValues(mapper.query(TestRecord, { key: item.key }, { readConsistency: 'strong' })), _q; _q = yield _p.next(), !_q.done;) {
                const element = _q.value;
                expect(element).toEqual(item);
            }
        }
        catch (e_5_1) { e_5 = { error: e_5_1 }; }
        finally {
            try {
                if (_q && !_q.done && (_o = _p.return)) yield _o.call(_p);
            }
            finally { if (e_5) throw e_5.error; }
        }
    }));
});
//# sourceMappingURL=DataMapper.integ.js.map