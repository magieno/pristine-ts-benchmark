"use strict";
var __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {
    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }
    return new (P || (P = Promise))(function (resolve, reject) {
        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }
        function rejected(value) { try { step(generator["throw"](value)); } catch (e) { reject(e); } }
        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }
        step((generator = generator.apply(thisArg, _arguments || [])).next());
    });
};
Object.defineProperty(exports, "__esModule", { value: true });
exports.BatchWrite = exports.MAX_WRITE_BATCH_SIZE = void 0;
const BatchOperation_1 = require("./BatchOperation");
const itemIdentifier_1 = require("./itemIdentifier");
exports.MAX_WRITE_BATCH_SIZE = 25;
/**
 * Puts or deletes items from DynamoDB in batches of 25 or fewer via one or more
 * BatchWriteItem operations. The items may belong to any number of tables.
 *
 * The iterable of writes to perform may be synchronous or asynchronous and is
 * expected to yield tuples describing the writes to be performed. The first
 * member should be the table name, and the second should be {WriteRequest}
 * object that defines either a put request or a delete request.
 *
 * This method will automatically retry any write requests returned by DynamoDB
 * as unprocessed. Exponential backoff on unprocessed items is employed on a
 * per-table basis.
 */
class BatchWrite extends BatchOperation_1.BatchOperation {
    constructor() {
        super(...arguments);
        this.batchSize = exports.MAX_WRITE_BATCH_SIZE;
    }
    doBatchRequest() {
        return __awaiter(this, void 0, void 0, function* () {
            const inFlight = [];
            const operationInput = { RequestItems: {} };
            let batchSize = 0;
            while (this.toSend.length > 0) {
                const [tableName, marshalled] = this.toSend.shift();
                inFlight.push([tableName, marshalled]);
                if (operationInput.RequestItems === undefined) {
                    operationInput.RequestItems = {};
                }
                if (operationInput.RequestItems[tableName] === undefined) {
                    operationInput.RequestItems[tableName] = [];
                }
                operationInput.RequestItems[tableName].push(marshalled);
                if (++batchSize === this.batchSize) {
                    break;
                }
            }
            const { UnprocessedItems = {} } = yield this.client.batchWriteItem(operationInput);
            const unprocessedTables = new Set();
            for (const table of Object.keys(UnprocessedItems)) {
                unprocessedTables.add(table);
                const unprocessed = [];
                for (const item of UnprocessedItems[table]) {
                    if (item.DeleteRequest || item.PutRequest) {
                        unprocessed.push(item);
                        const identifier = itemIdentifier_1.itemIdentifier(table, item);
                        for (let i = inFlight.length - 1; i >= 0; i--) {
                            const [tableName, attributes] = inFlight[i];
                            if (tableName === table &&
                                itemIdentifier_1.itemIdentifier(tableName, attributes) === identifier) {
                                inFlight.splice(i, 1);
                            }
                        }
                    }
                }
                this.handleThrottled(table, unprocessed);
            }
            this.movePendingToThrottled(unprocessedTables);
            const processedTables = new Set();
            for (const [tableName, marshalled] of inFlight) {
                processedTables.add(tableName);
                this.pending.push([tableName, marshalled]);
            }
            for (const tableName of processedTables) {
                this.state[tableName].backoffFactor =
                    Math.max(0, this.state[tableName].backoffFactor - 1);
            }
        });
    }
}
exports.BatchWrite = BatchWrite;
//# sourceMappingURL=BatchWrite.js.map